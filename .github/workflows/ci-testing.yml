name: CI testing

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on: # Trigger the workflow on push or pull request, but only for the main branch
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, reopened, ready_for_review, synchronize]

defaults:
  run:
    shell: bash

jobs:
  pytester:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest", "macos-13", "windows-latest"]
        python-version: ["3.9"]

    # Timeout: https://stackoverflow.com/a/59076067/4521646
    timeout-minutes: 35
    env:
      TORCH_URL: "https://download.pytorch.org/whl/cpu/torch_stable.html"

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Display dependencies
        run: |
          cat requirements.txt
          cat requirements/test.txt

      - name: Get pip cache dir
        id: pip-cache
        run: echo "dir=$(pip cache dir)" >> $GITHUB_OUTPUT

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: ${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requires }}-pip-

      - name: Install package & dependencies
        run: |
          pip --version
          pip install -e ".[extras]" -r requirements/test.txt -U -q --find-links $TORCH_URL
          pip list

      - name: Tests
        run: coverage run --source litdata -m pytest tests -v

      - name: Statistics
        if: success()
        run: |
          coverage report
          coverage xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          env_vars: OS,PYTHON
          name: codecov-umbrella
          fail_ci_if_error: false

  testing-guardian:
    runs-on: ubuntu-latest
    needs: pytester
    if: always()
    steps:
      - run: echo "${{ needs.pytester.result }}"
      - name: failing...
        if: needs.pytester.result == 'failure'
        run: exit 1
      - name: cancelled or skipped...
        if: contains(fromJSON('["cancelled", "skipped"]'), needs.pytester.result)
        timeout-minutes: 1
        run: sleep 90
